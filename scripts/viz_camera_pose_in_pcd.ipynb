{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from loguru import logger as logger\n",
    "# import open3d as o3d\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# mesh_file = \"../data/Daiwu_sample/mesh.ply\"\n",
    "# trajectory_file = \"../data/Daiwu_sample/vo_pano.txt\"\n",
    "\n",
    "\n",
    "# mesh = o3d.io.read_triangle_mesh(mesh_file)\n",
    "# vertices = np.asarray(mesh.vertices)\n",
    "# logger.info(\"Vertices number in mesh.ply is {}\".format(len(vertices)))\n",
    "\n",
    "# trajectories = np.loadtxt(trajectory_file)\n",
    "\n",
    "\n",
    "# # Simulated data: Replace this with your actual point cloud data\n",
    "# # Example data format: [[x1, y1, z1], [x2, y2, z2], ...]\n",
    "# # point_cloud_data = np.random.rand(100, 3)  # Replace with your data\n",
    "\n",
    "# # Camera position and pose: Replace with your actual values\n",
    "# # camera_position = np.array([1.0, 2.0, 3.0])\n",
    "# # camera_pose = np.array([0.5, 0.5, 0.5, 0.5])  # [qw, qx, qy, qz]\n",
    "\n",
    "# # 遍历每个关键帧\n",
    "# camera_points = []\n",
    "# camera_poses = []\n",
    "# for idx, trajectory in tqdm(enumerate(trajectories), total=len(trajectories), desc='Processing keyframes'): # 获取相机姿态\n",
    "#     timestamp = trajectory[0]\n",
    "#     camera_point = trajectory[1:4]\n",
    "#     qx, qy, qz, qw = trajectory[4:]\n",
    "#     quaternion = [qw, qx, qy, qz]\n",
    "#     camera_points.append(camera_point)\n",
    "#     camera_poses.append(quaternion)\n",
    "\n",
    "\n",
    "# # Visualization\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# # Plot point cloud\n",
    "# ax.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2], c='b', marker='o', label='Point Cloud')\n",
    "\n",
    "# # Plot camera position\n",
    "# ax.scatter(camera_points[:, 0], camera_points[:, 1], camera_points[:, 2], c='r', marker='s', s=100, label='Camera Position')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from loguru import logger as logger\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm\n",
    "\n",
    "#  Visualization using Open3D\n",
    "def visualize_point_cloud_and_cameras(vertices, camera_poses):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(vertices)\n",
    "\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "\n",
    "    cnt = 0\n",
    "    for camera_pose in camera_poses:\n",
    "        cnt += 1\n",
    "        if (cnt == 255):\n",
    "            camera = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.6)\n",
    "        else:\n",
    "            camera = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.3)\n",
    "        camera.transform(camera_pose)\n",
    "        vis.add_geometry(camera)\n",
    "\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 19:43:36.187 | INFO     | __main__:<module>:6 - Vertices number in mesh.ply is 9462482\n",
      "Processing trajectories: 100%|██████████| 258/258 [00:00<00:00, 84806.46it/s]\n"
     ]
    }
   ],
   "source": [
    "mesh_file = \"../data/Daiwu_sample/mesh.ply\"\n",
    "trajectory_file = \"../data/Daiwu_sample/vo_pano.txt\"\n",
    "\n",
    "mesh = o3d.io.read_triangle_mesh(mesh_file)\n",
    "vertices = np.asarray(mesh.vertices)\n",
    "logger.info(\"Vertices number in mesh.ply is {}\".format(len(vertices)))\n",
    "\n",
    "trajectories = np.loadtxt(trajectory_file)\n",
    "\n",
    "# Extract camera poses\n",
    "camera_poses = []\n",
    "for trajectory in tqdm(trajectories, total=len(trajectories), desc='Processing trajectories'):\n",
    "    x, y, z, qx, qy, qz, qw = trajectory[1:]\n",
    "    quaternion = [qw, qx, qy, qz]\n",
    "    # rotation_matrix = np.array([[1 - 2 * (qz**2 + qw**2), 2 * (qx * qy - qz * qw), 2 * (qx * qz + qy * qw)],\n",
    "    #                             [2 * (qx * qy + qz * qw), 1 - 2 * (qx**2 + qw**2), 2 * (qy * qz - qx * qw)],\n",
    "    #                             [2 * (qx * qz - qy * qw), 2 * (qy * qz + qx * qw), 1 - 2 * (qx**2 + qy**2)]])\n",
    "    rotation_matrix = o3d.geometry.get_rotation_matrix_from_quaternion(quaternion) # TODO: check o3d rotation matrix input\n",
    "\n",
    "    transformation_matrix = np.eye(4)\n",
    "    transformation_matrix[:3, :3] = rotation_matrix\n",
    "    transformation_matrix[:3, 3] = np.array([x, y, z])\n",
    "    camera_poses.append(transformation_matrix)\n",
    "\n",
    "# Filter points based on z > 4\n",
    "filtered_vertices = vertices[vertices[:, 2] < 2]\n",
    "\n",
    "# Visualization\n",
    "visualize_point_cloud_and_cameras(filtered_vertices, camera_poses)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
